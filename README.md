# Python爬虫爬取百度百科页面

## 项目描述

本项目是一个简单的Python爬虫框架，用于爬取百度百科页面并提取有价值的数据。爬虫的架构设计如下：

- **爬虫调度器**：负责整个爬虫的调度工作。
- **URL管理器**：管理待爬取和已爬取的URL。
- **网页下载器**：使用`urllib2`库下载网页内容。
- **网页解析器**：使用`BeautifulSoup`库解析网页内容。
- **数据输出器**：将提取的数据输出到文件中。

## 目录结构

项目的目录结构如下：

```
- spider_main.py  # 爬虫调度器
- url_manager.py  # URL管理器
- html_downloader.py  # 网页下载器
- html_parser.py  # 网页解析器
- html_outputer.py  # 数据输出器
```

## 使用方法

1. **运行爬虫**：
   在终端或命令行中运行`spider_main.py`文件，即可启动爬虫程序。

      ```bash
         python spider_main.py
            ```

            2. **查看输出结果**：
               爬虫运行完毕后，会在当前目录下生成一个名为`output.html`的文件。该文件包含了爬取的词条及其解释。

               ## 注意事项

               - 本项目在macOS下开发，如果在其他操作系统下运行，可能需要根据具体情况调整代码。
               - 在macOS下，可以使用`alt+enter`快捷键添加相应的方法。

               ## 输出示例

               爬取完毕后，`output.html`文件的内容示例如下：

               ```html
               <html>
               <head><title>爬取结果</title></head>
               <body>
                   <h1>词条1</h1>
                       <p>词条1的解释内容...</p>
                           <h1>词条2</h1>
                               <p>词条2的解释内容...</p>
                                   ...
                                   </body>
                                   </html>
                                   ```

                                   ## 贡献

                                   欢迎对本项目进行改进和优化，可以通过提交Pull Request或提出Issue来参与贡献。

                                   ## 许可证

                                   本项目采用MIT许可证，详情请参阅`LICENSE`文件。

                                   ## 下载链接
                                   [Python爬虫爬取百度百科页面](https://pan.quark.cn/s/49959923f03b) 

                                   (备用: [备用下载](https://pan.baidu.com/s/11VXNGcve4uC-nNxzHUd66Q?pwd=1234))

                                   ## 说明

                                   该仓库仅用于学习交流，请勿用于商业用途。
